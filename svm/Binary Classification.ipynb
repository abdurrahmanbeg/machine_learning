{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification using Logistic Regression and SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you need to perform binary classification using Logistic Regression and SVMs. The dataset is provided to you. Please note the following:\n",
    "1. Use the dataset provided with train/val/test set. (Dataset-Binary-Train/Validate/Test.csv)\n",
    "2. You can use **LogisticRegression** and **SVC** from `sklearn` package:\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "3. You might need to look into data balancing, dealing with categorical values.\n",
    "4. For both the validation and test sets:\n",
    "    - Show confusion matrix\n",
    "    - Accuracy, Precision, Recall, F-1 score\n",
    "    - AUC\n",
    "    \n",
    "    The most important metrics in this problem are F1-Score and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(266, 9)\n",
      "['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8']\n",
      "(265, 8)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('Dataset-Binary-Test.csv', delimiter=',')\n",
    "print(np.shape(data))\n",
    "features = ['F1','F2','F3','F4','F5','F6','F7','F8']\n",
    "print(features)\n",
    "x_test = data[1:,0:8]\n",
    "y_test = data[1:,8]\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 9)\n",
      "(1000, 8)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('Dataset-Binary-Train.csv', delimiter=',')\n",
    "print(np.shape(data))\n",
    "x_train = data[1:,0:8]\n",
    "y_train = data[1:,8]\n",
    "print(np.shape(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 9)\n",
      "(219, 8)\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt('Dataset-Binary-Validate.csv', delimiter=',')\n",
    "print(np.shape(data))\n",
    "x_val = data[1:,0:8]\n",
    "y_val = data[1:,8]\n",
    "print(np.shape(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic_Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set score:  0.8949771689497716\n",
      "Test set score:  0.8264150943396227\n"
     ]
    }
   ],
   "source": [
    "regr = LogisticRegression()\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_val)\n",
    "y_pred_test = regr.predict(x_test)\n",
    "score = regr.score(x_val, y_val)\n",
    "print(\"Validation set score: \",score)\n",
    "print(\"Test set score: \", regr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Validation Set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[192   0]\n",
      " [ 23   4]]\n",
      "192 0 23 4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.50 %\n",
      "Precision: 100.00 %\n",
      "Recall: 14.81 %\n",
      "F1-Score:  0.26\n",
      "AUC:  0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %5.2f\" % (accuracy*100), \"%\")\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision: %5.2f\" % (precision*100), \"%\")\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Recall: %5.2f\" % (recall*100), \"%\")\n",
    "f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "print(\"F1-Score: %5.2f\" % (f1))\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print(\"AUC: %5.2f\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Test Set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218   0]\n",
      " [ 46   1]]\n",
      "218 0 46 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.64 %\n",
      "Precision: 100.00 %\n",
      "Recall:  2.13 %\n",
      "F1-Score:  0.04\n",
      "AUC:  0.51\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %5.2f\" % (accuracy*100), \"%\")\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision: %5.2f\" % (precision*100), \"%\")\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Recall: %5.2f\" % (recall*100), \"%\")\n",
    "f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "print(\"F1-Score: %5.2f\" % (f1))\n",
    "auc = roc_auc_score(y_test, y_pred_test)\n",
    "print(\"AUC: %5.2f\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set score:  0.9315068493150684\n",
      "Test set score:  0.9207547169811321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "regr = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "regr.fit(x_train, y_train)\n",
    "y_pred = regr.predict(x_val)\n",
    "y_pred_test = regr.predict(x_test)\n",
    "score = regr.score(x_val, y_val)\n",
    "print(\"Validation set score: \",score)\n",
    "print(\"Test set score: \", regr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[186   6]\n",
      " [  9  18]]\n",
      "186 6 9 18\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.15 %\n",
      "Precision: 75.00 %\n",
      "Recall: 66.67 %\n",
      "F1-Score:  0.71\n",
      "AUC:  0.82\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %5.2f\" % (accuracy*100), \"%\")\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision: %5.2f\" % (precision*100), \"%\")\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Recall: %5.2f\" % (recall*100), \"%\")\n",
    "f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "print(\"F1-Score: %5.2f\" % (f1))\n",
    "auc = roc_auc_score(y_val, y_pred)\n",
    "print(\"AUC: %5.2f\" % (auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[216   2]\n",
      " [ 19  28]]\n",
      "216 2 19 28\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_test).ravel()\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(tn,fp,fn,tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.08 %\n",
      "Precision: 93.33 %\n",
      "Recall: 59.57 %\n",
      "F1-Score:  0.73\n",
      "AUC:  0.79\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (tn + fp + fn + tp)\n",
    "print(\"Accuracy: %5.2f\" % (accuracy*100), \"%\")\n",
    "precision = tp / (tp + fp)\n",
    "print(\"Precision: %5.2f\" % (precision*100), \"%\")\n",
    "recall = tp / (tp + fn)\n",
    "print(\"Recall: %5.2f\" % (recall*100), \"%\")\n",
    "f1 = 2 * ((precision*recall)/(precision+recall))\n",
    "print(\"F1-Score: %5.2f\" % (f1))\n",
    "auc = roc_auc_score(y_test, y_pred_test)\n",
    "print(\"AUC: %5.2f\" % (auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
